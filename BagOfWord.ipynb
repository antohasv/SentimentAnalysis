{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 8836: expected 4 fields, saw 5\n",
      "\n",
      "Skipping line 535882: expected 4 fields, saw 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_post = pd.read_csv(\"Sentiment_Analysis_Dataset.csv\", header=0, delimiter=\",\", error_bad_lines=False, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_post = all_post.drop(\"SentimentSource\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_post = all_post.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#slice posts in two part: train and test. Get 10% for test.\n",
    "test_len = int(round(all_post.shape[0] * 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157861"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = all_post[0: 20000]#[test_len:]#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = all_post[20000: 40000]#[:test_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x = test_df.SentimentText[9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emo_repl = {\n",
    "    # positive emoticons\n",
    "    \"&lt;3\": \" good \",\n",
    "    \":d\": \" good \",  # :D in lower case\n",
    "    \":dd\": \" good \",  # :DD in lower case\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "\n",
    "    # negative emoticons:\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":S\": \" bad \",\n",
    "    \":-S\": \" bad \",\n",
    "}\n",
    "\n",
    "emo_repl_order = [s for (lenk, s) in reversed(sorted([(len(k), k)for k in emo_repl.keys()]))]\n",
    "\n",
    "def clean_post(raw_post):\n",
    "    import HTMLParser \n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    #Download package stopwords and stemmer use:\n",
    "    #import nltk\n",
    "    #nltk.download()\n",
    "    \n",
    "    #url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    #raw_post = re.sub(url_pattern, '', raw_post, flags=re.MULTILINE)\n",
    "    for k in emo_repl_order:\n",
    "        raw_post = raw_post.replace(k, emo_repl[k])\n",
    "    \n",
    "    raw_post = HTMLParser.HTMLParser().unescape(raw_post.decode('utf-8')) #&quot - to symbol representation\"\n",
    "    \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_post)\n",
    "    lower_case = letters_only.lower()\n",
    "    words = lower_case.split()\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_posts(raw_posts):\n",
    "    clean_posts = []\n",
    "    for i in xrange(0, raw_posts.SentimentText.size):\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(\"{0} completed\".format(i + 1))\n",
    "        clean_posts.append(clean_post(raw_posts.SentimentText[i]))\n",
    "    return clean_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_bag_of_words(clean_posts):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 5000) \n",
    "    data_features = vectorizer.fit_transform(clean_posts)\n",
    "    #vocab = vectorizer.get_feature_names()\n",
    "    return data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed\n",
      "20000 completed\n"
     ]
    }
   ],
   "source": [
    "clean_train_posts = clean_posts(train_df)\n",
    "data_train_features = create_bag_of_words(clean_train_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "forest = forest.fit(data_train_features, train_df.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed\n",
      "20000 completed\n"
     ]
    }
   ],
   "source": [
    "clean_test_posts = clean_posts(test_df)\n",
    "data_test_features = create_bag_of_words(clean_test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = forest.predict(data_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df['Sentiment_Result'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df['Sum_Result'] = (test_df.Sentiment + test_df.Sentiment_Result) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5128"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum(test_df.Sum_Result) / (np.size(test_df.Sum_Result) * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-2beb20cf2e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bag_of_Words_model.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "output.to_csv(\"Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "#dist = np.sum(train_data_features, axis=0)\n",
    "#for tag, count in zip(vocab, dist):\n",
    "#    print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result2= model.fit(data_train_features, train_df.Sentiment).predict(data_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeline = pd.read_csv(\"timeline.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>672190736373325824</td>\n",
       "      <td>RT @strategyzer: Train 10+ ppl from your team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>672185139992989696</td>\n",
       "      <td>Make sure to check the Proposed Schedule Chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672184920660426752</td>\n",
       "      <td>Coffee &amp;amp; Ice Cream are now being served in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>672180762163019776</td>\n",
       "      <td>RT @waynebeaton: Visualizing Java 9 Module Rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>672177601566347264</td>\n",
       "      <td>Afternoon Sponsored Sessions are now underway!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>672166930267152385</td>\n",
       "      <td>List map by @Flat_Studio on @dribbble https://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>672164982163816448</td>\n",
       "      <td>Track every mile &amp;amp; moment to breaking thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>672164596153606144</td>\n",
       "      <td>Come join #google at the 10th #andevcon Women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>672163381160226816</td>\n",
       "      <td>RT @brunoborges: To celebrate 10,000+ follower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>672159509159256064</td>\n",
       "      <td>Lunch is served in Grand Ballroom B and the Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>672158523279605760</td>\n",
       "      <td>If you're wondering what the stream was all ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>672158219230306304</td>\n",
       "      <td>A9: Once you get \"Hello World\" on your phone t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>672158051806220288</td>\n",
       "      <td>A9: Great question! Don't be intimidated: Get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>672157722700218368</td>\n",
       "      <td>Circuits &amp;amp; Electronics with @MIT Professor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>672156732185939969</td>\n",
       "      <td>A8: ...supporting such a large, diverse, and g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>672156252265308161</td>\n",
       "      <td>A8: At Google we support them through docs, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>672155864464101377</td>\n",
       "      <td>A8: We love the Android dev community! New dev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TweetId                                          TweetText\n",
       "0   672190736373325824  RT @strategyzer: Train 10+ ppl from your team ...\n",
       "1   672185139992989696  Make sure to check the Proposed Schedule Chang...\n",
       "2   672184920660426752  Coffee &amp; Ice Cream are now being served in...\n",
       "3   672180762163019776  RT @waynebeaton: Visualizing Java 9 Module Rel...\n",
       "4   672177601566347264  Afternoon Sponsored Sessions are now underway!...\n",
       "5   672166930267152385  List map by @Flat_Studio on @dribbble https://...\n",
       "6   672164982163816448  Track every mile &amp; moment to breaking thro...\n",
       "7   672164596153606144  Come join #google at the 10th #andevcon Women ...\n",
       "8   672163381160226816  RT @brunoborges: To celebrate 10,000+ follower...\n",
       "9   672159509159256064  Lunch is served in Grand Ballroom B and the Wo...\n",
       "10  672158523279605760  If you're wondering what the stream was all ab...\n",
       "11  672158219230306304  A9: Once you get \"Hello World\" on your phone t...\n",
       "12  672158051806220288  A9: Great question! Don't be intimidated: Get ...\n",
       "13  672157722700218368  Circuits &amp; Electronics with @MIT Professor...\n",
       "14  672156732185939969  A8: ...supporting such a large, diverse, and g...\n",
       "15  672156252265308161  A8: At Google we support them through docs, on...\n",
       "16  672155864464101377  A8: We love the Android dev community! New dev..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
